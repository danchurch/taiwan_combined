{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One big biome table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I am hoping to make comparisons of wood and leaf endophyte environmental patterns, I need to combine these datasets early in the biomformatics pipeline, to make them as comparable as possible. We'll try to stick to the [usearch (uparse)](http://drive5.com/usearch/) pipeline for the process, as much as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='environment'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Work environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working directory, on my machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "cd /home/daniel/Documents/Taiwan_data/combined/combo_biome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using the [usearch (uparse)](http://drive5.com/usearch/) pipeline, version usearch v8.1.1861_i86linux32 on my personal machine, and the equivalent 64-bit version on our computing cluster [ACISS](http://aciss-computing.uoregon.edu/). These programs are abbreviated (soft linked) to \"usearch81\" and \"usearch\", respectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='mergepairs'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging paired-end reads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's re-pair all readsets in the same manner, except for Roo's stromatal readset, which he aligned by hand. \n",
    "\n",
    "First, the leaf study reads include a split 6+6 bp barcode scheme for identifying reads, so these need to be clipped from one read and combined on the other. I wrote a python script for this, let's see if it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "./BCunsplit4.py Roo_R2.fastq Roo_R1.fastq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This outputs two files, \"rearranged_Roo_R2.fastq\" and \"rearranged_Roo_R2.fastq\"\n",
    "\n",
    "Next we trim a little to make sure we doing our alignments with high quality base calls. The sites for trimming are decided by looking at the raw reads [(see below)](#quality), and finding where quality begins to drop off. \n",
    "To trim, we'll use the [FASTX-toolkit](http://hannonlab.cshl.edu/fastx_toolkit/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "## wood\n",
    "fastx_trimmer -l 255 -i woodR1.fastq -o woodR1_trimmed.fastq\n",
    "fastx_trimmer -l 210 -i woodR2.fastq -o woodR2_trimmed.fastq\n",
    "\n",
    "## leaves. These lengths were decided by Roo\n",
    "fastx_trimmer -l 263 -i rearranged_Roo_R1.fastq -o Roo_R1_trimmed.fastq\n",
    "fastx_trimmer -l 170 -i rearranged_Roo_R2.fastq -o Roo_R2_trimmed.fastq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the actual pairing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "## wood, let's pair both trimmed and untrimmed just to compare:\n",
    "usearch -fastq_mergepairs woodR1.fastq -reverse woodR2.fastq  -fastqout woodtrimmedmerged.fastq -notrunclabels\n",
    "usearch -fastq_mergepairs woodR1.fastq -reverse woodR2.fastq -fastqout woodmerged.fastq -notrunclabels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"-notrunclabels\" tag above asks usearch to keep the entire label of the forward reads, which is necessary because the wood reads, which are more recently sequenced than the leaf reads, contain sample info in their identifier lines. The leaves do not require this, their sample info is still in the sequence itself, to be use to [demultiplex](#demult) them, later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** typical report from these:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "usearch v8.1.1803_i86linux64, 74.2Gb RAM, 12 cores\n",
    "(C) Copyright 2013-15 Robert C. Edgar, all rights reserved.\n",
    "http://drive5.com/usearch\n",
    "\n",
    "Licensed to: ronh@molbio.uoregon.edu\n",
    "\n",
    "<br>03:02 925Mb  100.0% 95.6% merged<br>5567799  Pairs (5.6M)<br>5323274  Merged (5.3M, 95.61%)<br>2067236  Alignments with zero diffs (37.13%)<br>0  Fwd tails Q <= 2 trimmed (0.00%)<br>15  Rev tails Q <= 2 trimmed (0.00%)<br>244525  No alignment found (4.39%)<br>0  Alignment too short (< 16) (0.00%)<br>4512849  Staggered pairs (81.05%) merged & trimmed<br>239.63  Mean alignment length\n",
    "259.16  Mean merged read length<br>3.81  Mean fwd expected errors<br>6.27  Mean rev expected errors<br>1.57  Mean merged expected errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These numbers look pretty good. Many of the erroneous reads will be taken out below, in a [quality filtering](#qf) step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "## leaves\n",
    "usearch -fastq_mergepairs Roo_R2.fastq -reverse Roo_R1.fastq -fastqout leafmerged.fastq\n",
    "usearch -fastq_mergepairs Roo_R2_trimmed.fastq -reverse Roo_R1_trimmed.fastq -fastqout leaftrimmedmerged.fastq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did trimming do to our reads? Let's take a look. To plot these we'll use the [fastx wrapper](http://hannonlab.cshl.edu/fastx_toolkit/commandline.html#fastq_quality_boxplot_usage) for [gnuplot](http://www.gnuplot.info/), which I've tinkered with just a little to change up the crowded axes of the original setup. Fastx requires that we first compile the quality data from the fastq files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "## wood quality stats:\n",
    "fastx_quality_stats -i woodR1.fastq -o woodR1_fastxstats.txt\n",
    "fastx_quality_stats -i woodR2.fastq -o woodR2_fastxstats.txt\n",
    "fastx_quality_stats -i woodR1_trimmed.fastq -o woodR1_fastxstats.txt\n",
    "fastx_quality_stats -i woodR2_trimmed.fastq -o woodR2_fastxstats.txt\n",
    "fastx_quality_stats -i woodmerged.fastq -o woodmerged_fastxstats.txt\n",
    "fastx_quality_stats -i woodtrimmedmerged.faestq -o woodtrimmedmerged_fastxstats.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## leaf quality stats:\n",
    "fastx_quality_stats -i Roo_R1.fastq -o Roo_R1_fastxstats.txt\n",
    "fastx_quality_stats -i Roo_R2.fastq -o Roo_R2_fastxstats.txt\n",
    "fastx_quality_stats -i Roo_R1_trimmed.fastq -o Roo_R1_trimmed_fastxstats.txt\n",
    "fastx_quality_stats -i Roo_R2_trimmed.fastq -o Roo_R2_trimmed_fastxstats.txt\n",
    "fastx_quality_stats -i leafmerged.fastq -o leafmerged_fastxstats.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the graphics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "## wood graphics\n",
    "./dan_plot.sh -i woodR1_fastxstats.txt -o woodR1_quality.png\n",
    "./dan_plot.sh -i woodR2_fastxstats.txt -o woodR2_quality.png\n",
    "./dan_plot.sh -i  woodR1_trimmed_fastxstats.txt -o woodR1_trimmed_quality.png\n",
    "./dan_plot.sh -i  woodR2_trimmed_fastxstats.txt -o woodR2_trimmed_quality.png\n",
    "./dan_plot.sh -i woodmerged_fastxstats.txt -o woodmerged_quality.png\n",
    "./dan_plot.sh -i  woodtrimmedmerged_fastxstats.txt -o woodtrimmedmerged_quality.png\n",
    "\n",
    "## leaf graphics\n",
    "./dan_plot.sh -i  Roo_R1_trimmed_fastxstats.txt -o Roo_R1_trimmed_quality.png\n",
    "./dan_plot.sh -i  Roo_R2_trimmed_fastxstats.txt -o Roo_R2_trimmed_quality.png\n",
    "./dan_plot.sh -i leaftrimmedmerged_fastxstats.txt -o leaftrimmedmerged_quality.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='quality'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **untrimmed wood R1** reads look like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='woodR1_quality.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare to **trimmed wood R1** reads:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='woodR1_trimmed_quality.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **untrimmed wood R2** reads look like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='woodR2_quality.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare to **trimmed wood R2** reads:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='woodR2_trimmed_quality.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the **untrimmed, merged wood** file looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='woodmerged_quality.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously some problems here. So compare to the **merged, trimmed wood** reads:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='woodtrimmedmerged_quality.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks much better, but still a large dip in quality around 15 bp. More on this later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Roo has already decided the trimming sites for his leaf data [(see above)](#mergepairs). Skip to the trimmed leaf R1 reads:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='Roo_R1_trimmed_quality.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trimmed leaf R2 reads:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='Roo_R2_trimmed_quality.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trimmed, merged leaf reads:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='leaftrimmedmerged_quality.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In both leaves and wood, I think we've vastly improved the situation by merging. The nice thing about using the usearch merging algorithms is that they use a bayesian approach to calculating the q-scores of paired reads, so that agreements on base calls between R1 and R2 improve Q scores, and disagreements reduce them. The reduction by disagreement is proportional to the confidence of the two base calls at a site, so if the disagreement occurs at the end of a read, where quality is lower, the higher (more reliable) Q has a much greater influence on the final q-score of a base call. Check out the explanation [here](http://drive5.com/usearch/manual/exp_errs.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='qf'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuing with the usearch pipeline, let's do some quality filtering. We'll use the [expected error approach](http://drive5.com/usearch/manual/exp_errs.html). We can set error cutoff of 1% of all bases in a read, meaning that a read of length 400 bp is thrown out if it likely contains 4 or more erroneous bases. I think this is permissable, given our OTU clustering will ultimately be done at 95% similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "## wood sequences\n",
    "usearch -fastq_filter woodtrimmedmerged.fastq -fastq_maxee_rate .01 -fastqout wood_filtered.fastq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "usearch v8.1.1803_i86linux64, 74.2Gb RAM, 12 cores\n",
    "(C) Copyright 2013-15 Robert C. Edgar, all rights reserved.\n",
    "http://drive5.com/usearch\n",
    "\n",
    "Licensed to: ronh@molbio.uoregon.edu\n",
    "\n",
    "01:04 857Mb  100.0% Filtering, 85.4% passed\n",
    "   5323274  FASTQ recs (5.3M)              \n",
    "   4548698  Converted (4.5M, 85.4%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "## leaves\n",
    "usearch -fastq_filter leaftrimmedmerged.fastq -fastq_maxee_rate 0.01 -fastqout leaf_filtered.fastq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "usearch v8.1.1803_i86linux64, 529Gb RAM, 32 cores\n",
    "(C) Copyright 2013-15 Robert C. Edgar, all rights reserved.\n",
    "http://drive5.com/usearch\n",
    "\n",
    "Licensed to: ronh@molbio.uoregon.edu\n",
    "\n",
    "07:01 2.4Gb  100.0% Filtering, 90.7% passed\n",
    "  16701565  FASTQ recs (16.7M)             \n",
    "  15145323  Converted (15.1M, 90.7%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect these graphically as above, to see if avg read quality has improved. Not placing this here because the graphs look basically the same before and after filtering. But notice that we drop 15% of wood reads, and 9% of the leaf reads. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='fastq2fasta'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert from fastq to fasta format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've merged paired ends and done some quality filtering to ensure that we've hopefully mostly eliminated sequencer error (hah! see [index bleed](#bleed) below), let's convert to fasta as required by most downstream steps. Using FASTX toolkit again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "fastq_to_fasta -n -i leaf_filtered.fastq -o  leaf.fasta\n",
    "fastq_to_fasta -n -i wood_filtered.fastq -o  wood.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"-n\" flag tells fastx to retain sequences with \"N\" basecalls. Otherwise, these are removed, by default. Since ~1/2 of our leaf reads contain an \"N\", we need these. A single N basecall is an acceptable loss of information, OTU clustering and taxonomic assignments should be to deal with this. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"demult\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Demultiplex leaf reads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Roo's leaf reads were prepped at an earlier date than the wood reads. At the time of their sequencing, the standard method for denoting sample identities was to look for the presence of 12 bp golay barcodes, the ones that we cut and pasted when we [merged paired end reads](#mergepairs). For probably the only time in this pipeline, we will use a [qiime](http://qiime.org/) script, [\"demultiplex_fasta.py\"](http://qiime.org/scripts/demultiplex_fasta.html) that was made to parse samples by these golay barcodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script requires a mapping file that lists the barcodes and their accompanying sample info, plus a \"linkerprimersequence\". I use a map file supplied by Roo. I do not know what a \"linkerprimersequence\" is, I believe this is supplied by the illumina software. The script seems to prefer .tsv format to .csv, and looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#SampleID\tBarcodeSequence\tLinkerPrimerSequence\r\n",
      "1Leaf\tACCCATATATCC\tGCTGCGTTCTTCATCGATGC\r\n",
      "2Leaf\tACCCATAAGACG\tGCTGCGTTCTTCATCGATGC\r\n",
      "3Leaf\tTCGCCAGAACCA\tGCTGCGTTCTTCATCGATGC\r\n",
      "4Leaf\tACCCATATCAAA\tGCTGCGTTCTTCATCGATGC\r\n",
      "5Leaf\tACCCATATAGTA\tGCTGCGTTCTTCATCGATGC\r\n",
      "6Leaf\tACCCATCTACAG\tGCTGCGTTCTTCATCGATGC\r\n",
      "7Leaf\tACCCATCATACC\tGCTGCGTTCTTCATCGATGC\r\n",
      "8Leaf\tACCCATCATTAT\tGCTGCGTTCTTCATCGATGC\r\n",
      "9Leaf\tACCCATCTATCT\tGCTGCGTTCTTCATCGATGC\r\n"
     ]
    }
   ],
   "source": [
    "head leaf_sample_map.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "demultiplex_fasta.py -m leaf_sample_map.tsv -f leaf.fasta -o ./leaf_demult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This produces a folder with a log file and a file called \"demultiplexed_seqs.fna\". I will rename this to \"leaf.fna\" and bring it into our working directory. We can remove primers from the sequences now. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove primers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCR Primers in our wood reads were not included in these sequences, because they are used as part of the sequencing primers. The leaf reads, however, still contain our forward and reverse PCR primers. To remove these, we just clip the appropriate number of BPs from each end. We'll use the FASTX toolkit again. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long are our primers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\r\n",
      "20\r\n"
     ]
    }
   ],
   "source": [
    "##ITS1F\n",
    "expr length \"CTTGGTCATTTAGAGGAAGTAA\"\n",
    "## ITS2\n",
    "expr length \"GCTGCGTTCTTCATCGATGC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "fastx_trimmer -f 23 -i leaf.fna | fastx_trimmer -t 20 -o leaf_noprim.fna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Floating primers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In both of our read sets, \"floating\" primer sequences appear. This happens in other studies, as indicated by [Bálint et al. (2014)](http://onlinelibrary.wiley.com/doi/10.1002/ece3.1107/abstract;jsessionid=FBCBBBE428CAA870889926051DBC9927.f04t02). As advised by these authors, I remove the sequences that contain these floating primers with a script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "## ITS1F\n",
    "grep CTTGGTCATTTAGAGGAAGTAA wood.fasta | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "129"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "## ITS2\n",
    "grep GCTGCGTTCTTCATCGATGC wood.fasta | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not many. This doesn't include the reverse complements that also occur. To remove these floating primers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "## wood\n",
    "./floatingprimers.py wood.fasta wood_defloat.fasta CTTGGTCATTTAGAGGAAGTAA GCTGCGTTCTTCATCGATGC\n",
    "## leaves\n",
    "./floatingprimers.py leaf.fna leaf_defloat.fna CTTGGTCATTTAGAGGAAGTAA GCTGCGTTCTTCATCGATGC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arguments for this script: floatingprimers.py input_fasta_file output_fasta_file forward_primer reverse_primer. \n",
    "\n",
    "Reverse compliments are checked automatically from the forward and reverse primer sequences that are given as arguments.\n",
    "\n",
    "When doing this, we lose 460 reads from the wood sequences (0.01%), and "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chimera checking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to look for chimeras. We'll use the [uchime](http://www.drive5.com/usearch/manual/cmd_uchime_ref.html) algorithm, another step in the uparse/usearch pipeline. This is actually just the first of two checks for chimeras, the other being part of the [otu clustering](#otus).\n",
    "\n",
    "Get the latest [UNITE](https://unite.ut.ee/repository.php) database for usearch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2016-08-21 18:27:34--  https://unite.ut.ee/sh_files/uchime_reference_dataset_01.01.2016.zip\r\n",
      "Resolving unite.ut.ee (unite.ut.ee)... 2001:bb8:2002:500:ec4:7aff:fe0a:37b2, 193.40.5.164\r\n",
      "Connecting to unite.ut.ee (unite.ut.ee)|2001:bb8:2002:500:ec4:7aff:fe0a:37b2|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 8233914 (7.9M) [application/zip]\r\n",
      "Saving to: ‘uchime_reference_dataset_01.01.2016.zip’\r\n",
      "\r\n",
      "\r",
      " 0% [                                       ] 0           --.-K/s              \r",
      " 1% [                                       ] 89,823       386KB/s             \r",
      " 2% [>                                      ] 220,895      384KB/s             \r",
      " 7% [=>                                     ] 597,727      766KB/s             \r",
      "14% [====>                                  ] 1,203,935   1.19MB/s             \r",
      "27% [=========>                             ] 2,268,895   1.86MB/s             \r",
      "43% [================>                      ] 3,612,383   2.53MB/s             \r",
      "61% [======================>                ] 5,054,175   3.08MB/s             \r",
      "78% [=============================>         ] 6,495,967   3.51MB/s             \r",
      "96% [====================================>  ] 7,954,143   3.86MB/s             \r",
      "100%[======================================>] 8,233,914   3.95MB/s   in 2.0s   \r\n",
      "\r\n",
      "2016-08-21 18:27:37 (3.95 MB/s) - ‘uchime_reference_dataset_01.01.2016.zip’ saved [8233914/8233914]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "wget https://unite.ut.ee/sh_files/uchime_reference_dataset_01.01.2016.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unzip this, then use the ITS1 only database to check for chimeras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
